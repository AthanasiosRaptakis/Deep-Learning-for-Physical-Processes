{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable, Function\n",
    "from torch.nn import init\n",
    "#dtype = torch.cuda.FloatTensor\n",
    "dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state,filename):\n",
    "    torch.save(state, filename)  \n",
    "    print(\"State Saved\")\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006-12-27 12:00:00\n",
      "2016-01-01 12:00:00\n",
      "18\n",
      "(4015, 64, 64)\n",
      "torch.Size([3204, 4, 64, 64])\n",
      "torch.Size([3204, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "areanumbers = [18]#,2,3,3,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "\n",
    "batchsize=1\n",
    "#Train 80% of the dataset 4014\n",
    "train_test_split =3208\n",
    "val_amount = 0\n",
    "\n",
    "def hours_to_datestring(t):\n",
    "    t=int(t)\n",
    "    start = datetime.datetime(1950,1,1)\n",
    "    delta = datetime.timedelta(hours=t)\n",
    "    return (start+delta).strftime('%Y-%m-%d %H:%M:%S')\n",
    "# Limit to 2017-12-23 for standardisation\n",
    "times = np.load('dataset/times.npy')[:365*11]\n",
    "print(hours_to_datestring(times[0]))\n",
    "print(hours_to_datestring(times[3292]))\n",
    "\n",
    "areatemps=[]\n",
    "for i in areanumbers:\n",
    "    print(i)\n",
    "    nextarea = (np.load(f'dataset/by-area/area{i}.npy')[:365*11])\n",
    "    # Ignore leap days\n",
    "    for j in range(365):\n",
    "        days = nextarea[j::365]\n",
    "        days -= np.mean(days)\n",
    "        days /= np.std(days)\n",
    "    areatemps.append(nextarea)\n",
    "areatemps = np.array(areatemps)\n",
    "print(nextarea.shape)\n",
    "\n",
    "def input_indices(end_indices):\n",
    "    a = end_indices[:,None]\n",
    "    return np.concatenate((a-4,a-3,a-2,a-1),axis=1)\n",
    "\n",
    "def new_size(size):\n",
    "    return torch.Size((size[0]*size[1],))+size[2:]\n",
    "train_val_beginnings = 4+np.random.permutation(train_test_split-4)\n",
    "#train_val_beginnings = 4+np.arange(train_test_split-4)\n",
    "\n",
    "train_inputs = torch.from_numpy(areatemps[:,input_indices(train_val_beginnings[val_amount:])]).type(dtype)\n",
    "train_inputs = train_inputs.view(new_size(train_inputs.size()))\n",
    "print(train_inputs.shape)\n",
    "\n",
    "train_ends = torch.from_numpy(areatemps[:,train_val_beginnings[val_amount:]]).type(dtype)\n",
    "train_ends = train_ends.view(new_size(train_ends.size()))\n",
    "print(train_ends.shape)\n",
    "\n",
    "train_data = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_inputs,train_ends),\n",
    "                                         batch_size=batchsize, shuffle=True\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k(distsq,D,dt):\n",
    "    return torch.exp(-distsq/(4*D*dt))/(4*np.pi*D*dt)\n",
    "def gradientk(dist,D,dt):\n",
    "    return dist*torch.exp(-(dist**2).sum(1)/(4*D*dt))/(8*np.pi*D**2*dt**2)\n",
    "class GaussianConvolution(Function):\n",
    "    D = 0.45\n",
    "    dt = 1\n",
    "    @staticmethod\n",
    "    def forward(ctx, w, I):\n",
    "        ctx.save_for_backward(w,I)\n",
    "        interval=torch.arange(I.size()[-1]).type(dtype)\n",
    "        x1 = interval[None,:,None,None,None]\n",
    "        x2 = interval[None,None,:,None,None]\n",
    "        y1 = interval[None,None,None,:,None]\n",
    "        y2 = interval[None,None,None,None,:]\n",
    "        distsq = (x1-y1-w[:,0,:,:,None,None])**2+(x2-y2-w[:,1,:,:,None,None])**2\n",
    "        return (I[:,None,None,:,:]*k(distsq,GaussianConvolution.D,GaussianConvolution.dt)).sum(4).sum(3)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        w,I = ctx.saved_variables\n",
    "        w=w.data\n",
    "        I=I.data\n",
    "        interval=torch.arange(I.size()[-1]).type(dtype)\n",
    "        x1 = interval[None,:,None,None,None]\n",
    "        x2 = interval[None,None,:,None,None]\n",
    "        y1 = interval[None,None,None,:,None]\n",
    "        y2 = interval[None,None,None,None,:]\n",
    "        distx = (x1-w[:,0,:,:,None,None]-y1)[:,None,:,:,:,:].repeat(1,1,1,1,1,I.size()[-1])\n",
    "        disty = (x2-w[:,1,:,:,None,None]-y2)[:,None,:,:,:,:].repeat(1,1,1,1,I.size()[-1],1)\n",
    "        dist = torch.cat((distx,disty),dim=1)\n",
    "        grad = Variable((I[:,None,None,:,:]*gradientk(dist,GaussianConvolution.D,GaussianConvolution.dt)).sum(5).sum(4), requires_grad=False)\n",
    "        #I(x) only depends on w(x) and not on w(z) for z != x\n",
    "        return grad*grad_output[:,None,:,:], None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(*models):\n",
    "    for model in models:\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.ConvTranspose2d) or isinstance(module, nn.Linear):\n",
    "                #nn.init.kaiming_normal(module.weight)\n",
    "                nn.init.xavier_normal(module.weight,gain=1)\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data.zero_()\n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                module.weight.data.fill_(1)\n",
    "                module.bias.data.zero_()\n",
    "class _EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(_EncoderBlock, self).__init__()\n",
    "        self.cv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3,padding=1)\n",
    "        self.bn1 =  nn.BatchNorm2d(in_channels)\n",
    "        self.lr1 =  nn.LeakyReLU(0.1,inplace=True)\n",
    "        self.cv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3)\n",
    "        self.bn2 =  nn.BatchNorm2d(out_channels)\n",
    "        self.lr2 =  nn.LeakyReLU(0.1,inplace=True)\n",
    "        self.maxp = nn.MaxPool2d(kernel_size=3, stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual=x\n",
    "        #print(\"residual\",residual.shape)\n",
    "        out=self.cv1(x)\n",
    "        #print(\"cv1\",out.shape)\n",
    "        out=self.bn1(out)\n",
    "        #print(\"bn1\",out.shape)\n",
    "        out=self.lr1(out)\n",
    "        #print(\"lr1\",out.shape)\n",
    "        out+=residual\n",
    "        out=self.cv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out=self.lr2(out)\n",
    "        out=self.maxp(out)\n",
    "        return out\n",
    "\n",
    "class _DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super(_DecoderBlock, self).__init__()\n",
    "        self.cv1 =     nn.Conv2d(in_channels, in_channels, kernel_size=3,padding=1)\n",
    "        self.bn1 =     nn.BatchNorm2d(in_channels)\n",
    "        self.lr1 =     nn.LeakyReLU(0.1,inplace=True)\n",
    "        self.cv2 =     nn.Conv2d(in_channels, middle_channels, kernel_size=3)\n",
    "        self.bn2 =     nn.BatchNorm2d(middle_channels)\n",
    "        self.lr2 =     nn.LeakyReLU(0.1,inplace=True)\n",
    "        self.tcv =     nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual=x\n",
    "        #print(\"residual\",residual.shape)\n",
    "        out=self.cv1(x)\n",
    "        #print(\"cv1\",out.shape)\n",
    "        out=self.bn1(out)\n",
    "        #print(\"bn1\",out.shape)\n",
    "        out=self.lr1(out)\n",
    "        #print(\"lr1\",out.shape)\n",
    "        out+=residual\n",
    "        out=self.cv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out=self.lr2(out)\n",
    "        out=self.tcv(out)\n",
    "        return out\n",
    "\n",
    "class _CenterBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(_CenterBlock, self).__init__()\n",
    "        self.cv1 = nn.Conv2d(in_channels,in_channels , kernel_size=3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.lr1 = nn.LeakyReLU(0.1,inplace=True)\n",
    "        self.cv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.lr2 = nn.LeakyReLU(0.1,inplace=True)\n",
    "        self.tcv = nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual=x\n",
    "        out=self.cv1(x)\n",
    "        out=self.bn1(out)\n",
    "        out=self.lr1(out)\n",
    "        out+=residual\n",
    "        out=self.cv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out=self.lr2(out)\n",
    "        out=self.tcv(out)\n",
    "        return out\n",
    "\n",
    "class CDNN(nn.Module):\n",
    "    def __init__(self,k):\n",
    "        super(CDNN, self).__init__()\n",
    "        self.enc1 = _EncoderBlock(k,64)\n",
    "        self.enc2 = _EncoderBlock(64, 128)\n",
    "        self.enc3 = _EncoderBlock(128, 256)\n",
    "        self.enc4 = _EncoderBlock(256, 512)\n",
    "        self.dec4= _CenterBlock(512, 386)\n",
    "        self.dec3 = _DecoderBlock(386+256, 256, 194)\n",
    "        self.dec2 = _DecoderBlock(194+128, 128, 98)\n",
    "        self.dec1 = _DecoderBlock(98+64, 64, 2)\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(2,2, kernel_size=3),\n",
    "        )\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.enc1(x)\n",
    "        #print(\"x\",x.shape)\n",
    "        #print(\"enc1\",enc1.shape)\n",
    "        enc2 = self.enc2(enc1)\n",
    "        #print(\"enc2\",enc2.shape)\n",
    "        enc3 = self.enc3(enc2)\n",
    "        #print(\"enc3\",enc3.shape)\n",
    "        enc4 = self.enc4(enc3)\n",
    "        #print(\"enc4\",enc4.shape)\n",
    "        dec4 = self.dec4(enc4)\n",
    "        #print(\"dec4\",dec4.shape)\n",
    "        dec3 = self.dec3(torch.cat([dec4, F.upsample(enc3, dec4.size()[2:], mode='bilinear')], 1))\n",
    "        #print(\"dec3\",dec3.shape)\n",
    "        dec2 = self.dec2(torch.cat([dec3, F.upsample(enc2, dec3.size()[2:], mode='bilinear')], 1))\n",
    "        #print(\"dec2\",dec2.shape)\n",
    "        dec1 = self.dec1(torch.cat([dec2, F.upsample(enc1, dec2.size()[2:], mode='bilinear')], 1))\n",
    "        final = self.final(dec1)\n",
    "        W=F.upsample(final, x.size()[2:], mode='bilinear')\n",
    "        #print(\"W\",W.shape)\n",
    "\n",
    "        return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CDNN(4)\n",
    "\n",
    "warping = GaussianConvolution.apply\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  20\n",
      "100 59.462466806173325\n",
      "200 134.11078596115112\n",
      "300 62.717631101608276\n",
      "400 61.747832506895065\n",
      "500 55.093587920069695\n",
      "600 49.72612227499485\n",
      "700 47.63769246637821\n",
      "800 50.79288873076439\n",
      "900 45.826813980937004\n",
      "1000 45.16409333050251\n",
      "1100 48.38779094815254\n",
      "1200 44.568628653883934\n",
      "1300 49.67068001627922\n",
      "1400 51.980880841612816\n",
      "1500 49.14210547506809\n",
      "1600 46.28816843032837\n",
      "1700 43.422235161066055\n",
      "1800 44.86319401860237\n",
      "1900 41.73106178641319\n",
      "2000 47.54289948940277\n",
      "2100 45.31456145644188\n",
      "2200 43.10187664628029\n",
      "2300 45.355447202920914\n",
      "2400 44.21266309916973\n",
      "2500 43.87958471477032\n",
      "2600 40.60140861570835\n",
      "2700 46.41489861905575\n",
      "2800 45.700280755758286\n",
      "2900 43.68738594651222\n",
      "3000 40.04678601026535\n",
      "3100 45.36666922271252\n",
      "3200 43.01696968078613\n",
      "State Saved\n",
      "models/MSE/CDNN_MSE_Epoch=20.pth\n",
      "epoch =  21\n",
      "100 43.07311537861824\n",
      "200 42.54684357345104\n",
      "300 41.1342806071043\n",
      "400 38.67177537083626\n",
      "500 39.03800444304943\n",
      "600 41.8646254837513\n",
      "700 38.990924805402756\n",
      "800 43.20360590517521\n",
      "900 41.112010627985\n",
      "1000 37.635051533579826\n",
      "1100 41.33575004339218\n",
      "1200 44.23403114080429\n",
      "1300 42.32691505551338\n",
      "1400 42.654114946722984\n",
      "1500 43.04064141213894\n",
      "1600 41.153114289045334\n",
      "1700 38.370226204395294\n",
      "1800 41.428353264927864\n",
      "1900 39.71390154957771\n",
      "2000 37.44971679151058\n",
      "2100 43.242351934313774\n",
      "2200 39.63054935634136\n",
      "2300 39.86532999575138\n",
      "2400 38.81874290108681\n",
      "2500 39.90765564143658\n",
      "2600 37.95996122062206\n",
      "2700 36.46201206743717\n",
      "2800 38.57947087287903\n",
      "2900 37.6773334890604\n",
      "3000 38.119504034519196\n",
      "3100 40.52112662792206\n",
      "3200 41.13635114580393\n",
      "State Saved\n",
      "models/MSE/CDNN_MSE_Epoch=21.pth\n",
      "epoch =  22\n",
      "100 39.89137114584446\n",
      "200 41.11491113901138\n",
      "300 38.0733388364315\n",
      "400 38.770045295357704\n",
      "500 38.83538077771664\n",
      "600 36.18129417300224\n",
      "700 39.15172007679939\n",
      "800 41.137119710445404\n",
      "900 41.26555084437132\n",
      "1000 42.90530863404274\n",
      "1100 39.32158225774765\n",
      "1200 38.573868945240974\n",
      "1300 38.4015504270792\n",
      "1400 36.60527375340462\n",
      "1500 38.58941005170345\n",
      "1600 38.606769904494286\n",
      "1700 39.495700642466545\n",
      "1800 43.47647489607334\n",
      "1900 36.94085343927145\n",
      "2000 39.57636438310146\n",
      "2100 38.821543887257576\n",
      "2200 35.287999004125595\n",
      "2300 38.20232194662094\n",
      "2400 36.98138706386089\n",
      "2500 40.36225516349077\n",
      "2600 38.87189945578575\n",
      "2700 36.06319837272167\n",
      "2800 36.89600148797035\n",
      "2900 44.661844827234745\n",
      "3000 41.10191971063614\n",
      "3100 38.205583810806274\n",
      "3200 38.79701828956604\n",
      "State Saved\n",
      "models/MSE/CDNN_MSE_Epoch=22.pth\n",
      "epoch =  23\n",
      "100 37.8971201479435\n",
      "200 34.38506680727005\n",
      "300 37.60784015059471\n",
      "400 39.1303396075964\n",
      "500 39.712508738040924\n",
      "600 37.23770137131214\n",
      "700 37.489734411239624\n",
      "800 37.362793013453484\n",
      "900 36.97109308838844\n",
      "1000 38.41587332636118\n",
      "1100 35.78382885456085\n",
      "1200 37.3265019133687\n",
      "1300 37.55023695528507\n",
      "1400 38.699326664209366\n",
      "1500 36.28333340585232\n",
      "1600 38.44179134070873\n",
      "1700 38.588902339339256\n",
      "1800 38.86176323145628\n",
      "1900 35.24069285392761\n",
      "2000 36.65118062496185\n",
      "2100 35.640442319214344\n",
      "2200 36.19876468926668\n",
      "2300 36.915449887514114\n",
      "2400 35.438820362091064\n",
      "2500 33.70782591402531\n",
      "2600 34.762043714523315\n",
      "2700 36.388250447809696\n",
      "2800 33.96700040996075\n",
      "2900 33.917775958776474\n",
      "3000 39.24932286888361\n",
      "3100 38.54044163227081\n",
      "3200 35.307836920022964\n",
      "State Saved\n",
      "models/MSE/CDNN_MSE_Epoch=23.pth\n",
      "epoch =  24\n",
      "100 35.42009648680687\n",
      "200 37.31154829263687\n",
      "300 37.22654312849045\n",
      "400 34.52912846207619\n",
      "500 34.911930434405804\n",
      "600 37.11401204764843\n",
      "700 33.716966420412064\n",
      "800 34.370580799877644\n",
      "900 37.363256849348545\n",
      "1000 33.719140477478504\n",
      "1100 33.30984501540661\n",
      "1200 33.417424857616425\n",
      "1300 40.12894805520773\n",
      "1400 38.1960085183382\n",
      "1500 34.63724768906832\n",
      "1600 33.712533824145794\n",
      "1700 38.52677796781063\n",
      "1800 40.37518413364887\n",
      "1900 33.800172463059425\n",
      "2000 31.79557330906391\n",
      "2100 37.61450020968914\n",
      "2200 37.94920310378075\n",
      "2300 37.436018742620945\n",
      "2400 35.59126840531826\n",
      "2500 34.74549400806427\n",
      "2600 36.4060445278883\n",
      "2700 34.47660169750452\n",
      "2800 31.76260693371296\n",
      "2900 39.4491313919425\n",
      "3000 35.37197341769934\n",
      "3100 35.00181756913662\n",
      "3200 33.20158424973488\n",
      "State Saved\n",
      "models/MSE/CDNN_MSE_Epoch=24.pth\n",
      "epoch =  25\n",
      "100 32.75031465291977\n",
      "200 34.34073203802109\n",
      "300 43.08381897211075\n",
      "400 34.45902447402477\n",
      "500 35.71411123871803\n",
      "600 35.68624749779701\n",
      "700 35.78661960363388\n",
      "800 36.629446029663086\n",
      "900 33.32988581061363\n",
      "1000 35.907333850860596\n",
      "1100 35.74394639581442\n",
      "1200 37.47054959833622\n",
      "1300 36.38886300474405\n",
      "1400 32.75449136644602\n",
      "1500 34.90778812766075\n",
      "1600 35.52064526826143\n",
      "1700 35.10012785345316\n",
      "1800 36.62775845080614\n",
      "1900 31.906080350279808\n",
      "2000 31.81015305966139\n",
      "2100 33.509989604353905\n",
      "2200 33.90553814172745\n",
      "2300 37.46015179157257\n",
      "2400 38.147388219833374\n",
      "2500 37.15478506684303\n",
      "2600 38.232310116291046\n",
      "2700 37.39679363369942\n",
      "2800 33.6250853985548\n",
      "2900 35.06738241761923\n",
      "3000 34.11932782828808\n",
      "3100 34.40302559733391\n",
      "3200 31.157419465482235\n",
      "State Saved\n",
      "models/MSE/CDNN_MSE_Epoch=25.pth\n",
      "epoch =  26\n",
      "100 31.607530504465103\n",
      "200 35.38368862122297\n",
      "300 30.907798670232296\n",
      "400 42.123761996626854\n",
      "500 35.004781521856785\n",
      "600 33.242518946528435\n",
      "700 35.00574979186058\n",
      "800 33.91772608458996\n",
      "900 35.66494511067867\n",
      "1000 35.10940935462713\n",
      "1100 34.26742357760668\n",
      "1200 38.78570371866226\n",
      "1300 33.038769006729126\n",
      "1400 35.612184166908264\n",
      "1500 31.97453348338604\n",
      "1600 33.18480224907398\n",
      "1700 34.892401948571205\n",
      "1800 33.27391079813242\n",
      "1900 35.19221089780331\n",
      "2000 35.74132137745619\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-2fbb366fde2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mInput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mTarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-1f9e325cc00a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0menc4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m#print(\"enc4\",enc4.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mdec4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;31m#print(\"dec4\",dec4.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mdec3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdec4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-1f9e325cc00a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 277\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 torch.backends.cudnn.deterministic, torch.backends.cudnn.enabled)\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate=1e-3\n",
    "Iter_Size=100\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "losses = []\n",
    "for epoch in range(20,100):\n",
    "    print(\"epoch = \",epoch)\n",
    "    step=0\n",
    "    while step< len(train_data)-Iter_Size:\n",
    "        optimizer.zero_grad()\n",
    "        iter_loss=0\n",
    "        i=0\n",
    "        while(i<Iter_Size):\n",
    "            Input, Target = next(iter(train_data))\n",
    "            i=i+1\n",
    "            step=step+1\n",
    "            Input = Variable(Input,requires_grad=False)\n",
    "            Target = Variable(Target)\n",
    "            w = net(Input)\n",
    "            y_pred = warping(w, Input[:,-1])\n",
    "                \n",
    "            loss = loss_fn(y_pred, Target)/Iter_Size\n",
    "            loss.backward()\n",
    "            iter_loss+=loss.data[0]\n",
    "        print(step,iter_loss)\n",
    "        losses.append(iter_loss)\n",
    "        optimizer.step()\n",
    "    filename=\"models/MSE/CDNN_MSE_Epoch={}.pth\".format(epoch)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': net.state_dict(),\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "        'losses'    : losses,\n",
    "    },filename)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses)\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('Loss')\n",
    "plt.suptitle(\"MSE Loss for Area {0}\".format(areanumbers[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_ends[-1].cpu().numpy(),origin='lower')\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.imshow(y_pred.data[0].cpu().numpy(),origin='lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.training == True\n",
    "#.eval()\n",
    "#.train()\n",
    "\n",
    "# for loading\n",
    "#net2=CDNN(4)\n",
    "#net2.load_state_dict(torch.load(filename))\n",
    "#net2.eval()\n",
    "\n",
    "#checkpoint = torch.load(filename)\n",
    "#start_epoch = checkpoint['epoch']\n",
    "#net2.load_state_dict(checkpoint['state_dict'])\n",
    "#optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "#L=checkpoint['losses']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
